{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YkcXIr9UpO7uRKF4AZ_Gt3zPXJ-yUyCw",
      "authorship_tag": "ABX9TyNEHyR7+ZZSMmBaU3Q25FTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rht6226/BTP-DD/blob/main/Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmYvnnAYzHUz"
      },
      "source": [
        "import numpy as np\r\n",
        "import math\r\n",
        "import os.path\r\n",
        "import csv\r\n",
        "import glob\r\n",
        "import tensorflow as tf\r\n",
        "import h5py as h5py\r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\r\n",
        "from keras.models import Model, load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXuyZjSAORRa"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "from scipy.spatial import distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAv18ZOw0NiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7868b45f-212c-4dc5-db4e-cde95c77206e"
      },
      "source": [
        "import imageio\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from mlxtend.image import extract_face_landmarks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 to /root/mlxtend_data/shape_predictor_68_face_landmarks.dat.bz2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW2RyDm50WwG"
      },
      "source": [
        "def eye_aspect_ratio(eye):\r\n",
        "\tA = distance.euclidean(eye[1], eye[5])\r\n",
        "\tB = distance.euclidean(eye[2], eye[4])\r\n",
        "\tC = distance.euclidean(eye[0], eye[3])\r\n",
        "\tear = (A + B) / (2.0 * C)\r\n",
        "\treturn ear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScIfiR4S0l02"
      },
      "source": [
        "def mouth_aspect_ratio(mouth):\r\n",
        "    A = distance.euclidean(mouth[14], mouth[18])\r\n",
        "    C = distance.euclidean(mouth[12], mouth[16])\r\n",
        "    mar = (A ) / (C)\r\n",
        "    return mar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt8U-XuL0odz"
      },
      "source": [
        "def circularity(eye):\r\n",
        "    A = distance.euclidean(eye[1], eye[4])\r\n",
        "    radius  = A/2.0\r\n",
        "    Area = math.pi * (radius ** 2)\r\n",
        "    p = 0\r\n",
        "    p += distance.euclidean(eye[0], eye[1])\r\n",
        "    p += distance.euclidean(eye[1], eye[2])\r\n",
        "    p += distance.euclidean(eye[2], eye[3])\r\n",
        "    p += distance.euclidean(eye[3], eye[4])\r\n",
        "    p += distance.euclidean(eye[4], eye[5])\r\n",
        "    p += distance.euclidean(eye[5], eye[0])\r\n",
        "    return 4 * math.pi * Area /(p**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUaA0Nu10r_C"
      },
      "source": [
        "def mouth_over_eye(eye):\r\n",
        "    ear = eye_aspect_ratio(eye)\r\n",
        "    mar = mouth_aspect_ratio(eye)\r\n",
        "    mouth_eye = mar/ear\r\n",
        "    return mouth_eye"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpQ4lim90vov"
      },
      "source": [
        "def getFrame(vidcap, sec):\r\n",
        "    start = 180000\r\n",
        "    vidcap.set(cv2.CAP_PROP_POS_MSEC, start + sec*1000)\r\n",
        "    hasFrames,image = vidcap.read()\r\n",
        "    return hasFrames, image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebYLHQcWRZ5p"
      },
      "source": [
        "def extract_data_from_video(video_path, label):\r\n",
        "    data = []\r\n",
        "    labels = []\r\n",
        "    vidcap = cv2.VideoCapture(video_path)\r\n",
        "    sec = 0\r\n",
        "    frameRate = 1\r\n",
        "    success, image  = getFrame(vidcap, sec)\r\n",
        "    count = 0\r\n",
        "    misses = 0\r\n",
        "\r\n",
        "    while success and count < 240: \r\n",
        "        landmarks = extract_face_landmarks(image)\r\n",
        "        if sum(sum(landmarks)) != 0:\r\n",
        "            count += 1\r\n",
        "            data.append(landmarks)\r\n",
        "            labels.append(label)\r\n",
        "            sec = sec + frameRate\r\n",
        "            sec = round(sec, 2)\r\n",
        "            success, image = getFrame(vidcap, sec)\r\n",
        "\r\n",
        "            if ((count - 1) %30) == 0:\r\n",
        "                print(\"\\n{}/240:\".format(count), end='')\r\n",
        "            print(\">\", end='')\r\n",
        "\r\n",
        "        else:  \r\n",
        "            sec = sec + frameRate\r\n",
        "            sec = round(sec, 2)\r\n",
        "            misses += 1\r\n",
        "            success, image = getFrame(vidcap, sec)\r\n",
        "            \r\n",
        "            if ((misses) %30) == 0:\r\n",
        "                print(\"\\n{}/120:\".format(misses), end='')\r\n",
        "            print(\"x\", end='')\r\n",
        "\r\n",
        "            \r\n",
        "\r\n",
        "        # break if no face in video\r\n",
        "        if (misses > 120 and count <=5):\r\n",
        "                break\r\n",
        "\r\n",
        "    return data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8vcAJkFO2Ey"
      },
      "source": [
        "def extract_data_from_folder(folderName):\r\n",
        "    base_path = '/content/drive/MyDrive/Drowsiness Detection/Dataset/'\r\n",
        "    folderPath = base_path + str(folderName) + '/'\r\n",
        "    files = os.listdir(folderPath)\r\n",
        "    data_all = []\r\n",
        "    labels_all = []\r\n",
        "    for f in files:\r\n",
        "        print('\\nExtracting data from {}/{}'.format(folderName, f))\r\n",
        "        video_path = '/content/drive/MyDrive/Drowsiness Detection/Dataset/' + folderName + '/' + str(f)\r\n",
        "        y = int(f.split('.')[0])\r\n",
        "        data, labels = extract_data_from_video(video_path, y)\r\n",
        "        data_all.append(data)\r\n",
        "        labels_all.append(labels)\r\n",
        "    return data_all, labels_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmurCFzshuU1"
      },
      "source": [
        "def extract_features_from_data(D):\r\n",
        "    features = []\r\n",
        "    for d in D:\r\n",
        "        eye = d[36:68]\r\n",
        "        ear = eye_aspect_ratio(eye)\r\n",
        "        mar = mouth_aspect_ratio(eye)\r\n",
        "        cir = circularity(eye)\r\n",
        "        mouth_eye = mouth_over_eye(eye)\r\n",
        "        features.append([ear, mar, cir, mouth_eye])\r\n",
        "    features = np.array(features)\r\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhuonBbsiSiU"
      },
      "source": [
        "def extraction(folderName):\r\n",
        "    data, labels = extract_data_from_folder(folderName)\r\n",
        "    D = []\r\n",
        "    for d in data:\r\n",
        "        for x in d:\r\n",
        "            D.append(x)\r\n",
        "\r\n",
        "    L = []\r\n",
        "\r\n",
        "    for l in labels:\r\n",
        "        for x in l:\r\n",
        "            L.append(x)\r\n",
        "\r\n",
        "    D = np.array(D)\r\n",
        "    L = np.array(L)\r\n",
        "\r\n",
        "    np.savez('/content/drive/MyDrive/Drowsiness Detection/Extracted_Data/{}.npz'.format(folderName), data=D, labels=L)\r\n",
        "\r\n",
        "    F = extract_features_from_data(D)\r\n",
        "\r\n",
        "    np.savez('/content/drive/MyDrive/Drowsiness Detection/Extracted_Features/{}.npz'.format(folderName), features=F, labels=L)\r\n",
        "\r\n",
        "    print(\"\\nExtraction for folder {} completed sucessfully...\".format(folderName))\r\n",
        "    print(\"Size of Facial Landmark Data : \", D.shape)\r\n",
        "    print(\"Size of Extracted Features : \", F.shape)\r\n",
        "    print(\"Size of Lables : \", L.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjyyzrh6R40V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5859e23-9abe-48e6-9670-9361de2eea13"
      },
      "source": [
        "extraction(\"37\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data from 37/5.mov\n",
            "\n",
            "1/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "31/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "61/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "91/240:>>>>>>>>>>>>>>>>>>>>>>>>"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlxtend/image/extract_face_landmarks.py:61: UserWarning: No face detected.\n",
            "  warnings.warn('No face detected.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x>>>>>>\n",
            "121/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "151/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "181/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "211/240:>>>>>>>>>x>>>>>>>>>>>>>>>>>>>>>\n",
            "Extracting data from 37/0.mov\n",
            "\n",
            "1/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "31/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "61/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "91/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "121/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "151/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "181/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "211/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Extracting data from 37/10.mov\n",
            "x\n",
            "1/240:>>>xxxx>x>>xx>x>>>>>>>>>>>>>>>>>>>>>>>\n",
            "31/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "61/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "91/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "121/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "151/240:>>>>>>>x>>x>>x>>>>>>>>>>>>>>>>>>>\n",
            "181/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>x>>xxx>\n",
            "211/240:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Extraction for folder 37 completed sucessfully...\n",
            "Size of Facial Landmark Data :  (720, 68, 2)\n",
            "Size of Extracted Features :  (720, 4)\n",
            "Size of Lables :  (720,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DOXQcnHtfk-"
      },
      "source": [
        "# All the features have been extracted into different files\r\n",
        "# Now we will be combining them into one.\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}